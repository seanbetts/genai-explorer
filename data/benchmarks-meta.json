[
  {
    "benchmark_id": "browse-comp",
    "benchmark_name": "BrowseComp",
    "benchmark_category": "agentic",
    "benchmark_paper": "https://openai.com/index/browsecomp/"
  },
  {
    "benchmark_id": "collie",
    "benchmark_name": "COLLIE",
    "benchmark_category": "agentic",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "complex-func-bench",
    "benchmark_name": "ComplexFuncBench",
    "benchmark_category": "agentic",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "if-eval",
    "benchmark_name": "IFEval",
    "benchmark_category": "agentic",
    "benchmark_paper": "https://arxiv.org/abs/2311.07911"
  },
  {
    "benchmark_id": "multi-if",
    "benchmark_name": "Multi-IF",
    "benchmark_category": "agentic",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "multi-challenge",
    "benchmark_name": "MultiChallenge",
    "benchmark_category": "agentic",
    "benchmark_paper": "https://scale.com/leaderboard/multichallenge"
  },
  {
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "Tau-bench Airline",
    "benchmark_category": "agentic",
    "benchmark_paper": "https://arxiv.org/pdf/2406.12045"
  },
  {
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "Tau-bench Retail",
    "benchmark_category": "agentic",
    "benchmark_paper": "https://arxiv.org/pdf/2406.12045"
  },
  {
    "benchmark_id": "aiders-polyglot",
    "benchmark_name": "Aider's Polyglot",
    "benchmark_category": "coding",
    "benchmark_paper": "https://aider.chat/docs/leaderboards/"
  },
  {
    "benchmark_id": "bird-sql",
    "benchmark_name": "Bird-SQL (Dev)",
    "benchmark_category": "coding",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "codeforces",
    "benchmark_name": "Codeforces",
    "benchmark_category": "coding",
    "benchmark_paper": "https://arxiv.org/html/2501.01257v2"
  },
  {
    "benchmark_id": "human-eval",
    "benchmark_name": "HumanEval",
    "benchmark_category": "coding",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "lcb",
    "benchmark_name": "LCB",
    "benchmark_category": "coding",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "live-code-bench-v5",
    "benchmark_name": "LiveCodeBench v5",
    "benchmark_category": "coding",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "benchmark_category": "coding",
    "benchmark_paper": "https://openai.com/index/introducing-swe-bench-verified/"
  },
  {
    "benchmark_id": "swe-lancer",
    "benchmark_name": "SWE-Lancer",
    "benchmark_category": "coding",
    "benchmark_paper": "https://openai.com/index/swe-lancer/"
  },
  {
    "benchmark_id": "swe-lancer-ic-swe-diamond",
    "benchmark_name": "SWE-Lancer: IC SWE Diamond",
    "benchmark_category": "coding",
    "benchmark_paper": "https://openai.com/index/swe-lancer/"
  },
  {
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench-Hard",
    "benchmark_category": "conversational",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "benchmark_category": "conversational",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-pro",
    "benchmark_category": "conversational",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "multilingual-mmlu",
    "benchmark_name": "Multilingual MMLU",
    "benchmark_category": "conversational",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "facts-grounding",
    "benchmark_name": "FACTS Grounding",
    "benchmark_category": "factuality",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "loft",
    "benchmark_name": "LOFT (128k)",
    "benchmark_category": "factuality",
    "benchmark_paper": "https://github.com/google-deepmind/loft"
  },
  {
    "benchmark_id": "mrcr",
    "benchmark_name": "MRCR (1M)",
    "benchmark_category": "factuality",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "simple-qa",
    "benchmark_name": "SimpleQA",
    "benchmark_category": "factuality",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "benchmark_category": "maths",
    "benchmark_paper": "https://artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions"
  },
  {
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "benchmark_category": "maths",
    "benchmark_paper": "https://artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions"
  },
  {
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8K",
    "benchmark_category": "maths",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "hidden-math",
    "benchmark_name": "HiddenMath",
    "benchmark_category": "maths",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "benchmark_category": "maths",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "math-500",
    "benchmark_name": "Math 500",
    "benchmark_category": "maths",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "math-vista",
    "benchmark_name": "MathVista",
    "benchmark_category": "maths",
    "benchmark_paper": "https://mathvista.github.io"
  },
  {
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "benchmark_category": "maths",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "co-vo-st2",
    "benchmark_name": "CoVoST2 (21 lang)",
    "benchmark_category": "multimodal",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "doc-vqa",
    "benchmark_name": "DocVQA",
    "benchmark_category": "multimodal",
    "benchmark_paper": "https://www.docvqa.org"
  },
  {
    "benchmark_id": "ego-schema",
    "benchmark_name": "EgoSchema",
    "benchmark_category": "multimodal",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "benchmark_category": "multimodal",
    "benchmark_paper": "https://mmmu-benchmark.github.io"
  },
  {
    "benchmark_id": "video-mme",
    "benchmark_name": "Video-MME",
    "benchmark_category": "multimodal",
    "benchmark_paper": "https://video-mme.github.io/home_page.html"
  },
  {
    "benchmark_id": "charxiv-reasoning",
    "benchmark_name": "CharXiv-Reasoning",
    "benchmark_category": "reasoning",
    "benchmark_paper": "https://charxiv.github.io"
  },
  {
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "benchmark_category": "reasoning",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "graphwalks-bfs",
    "benchmark_name": "Graphwalks BFS <128k accuracy",
    "benchmark_category": "reasoning",
    "benchmark_paper": "https://huggingface.co/datasets/openai/graphwalks"
  },
  {
    "benchmark_id": "humanitys-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "benchmark_category": "reasoning",
    "benchmark_paper": "https://agi.safe.ai"
  },
  {
    "benchmark_id": "simple-bench",
    "benchmark_name": "SimpleBench",
    "benchmark_category": "reasoning",
    "benchmark_paper": "https://simple-bench.com"
  },
  {
    "benchmark_id": "paper-bench",
    "benchmark_name": "PaperBench",
    "benchmark_category": "research",
    "benchmark_paper": "https://openai.com/index/paperbench/"
  },
  {
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "benchmark_category": "science",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "gpqa-diamond",
    "benchmark_name": "GPQA Diamond",
    "benchmark_category": "science",
    "benchmark_paper": "https://arxiv.org/pdf/2311.12022"
  },
  {
    "benchmark_id": "hellaswag",
    "benchmark_name": "Hellaswag",
    "benchmark_category": "reasoning",
    "benchmark_paper": null
  },
  {
    "benchmark_id": "arc",
    "benchmark_name": "ARC",
    "benchmark_category": "reasoning",
    "benchmark_paper": "https://arcprize.org/arc-agi"
  },
  {
    "benchmark_id": "chatbot-arena",
    "benchmark_name": "Chatbot Arena",
    "benchmark_category": "conversational",
    "benchmark_paper": "https://lmarena.ai"
  }
]